

<html>
<head>
<title>Shi-Sheng Huang's Homepage </title>
<style type="text/css">
body {
	margin-top: 30px;
	margin-bottom: 30px;
	margin-left: 100px;
	margin-right: 100px;
}
p {
	margin-top: 0px;
	margin-bottom: 0px;
}

.caption {
	font-size: 60px;
	font-weight: bold;
	color: #000;
	font-family: "Goudy Old Style";
}
.caption-1 {
	font-size: 20px;
	font-family: Tahoma, Geneva, sans-serif;
}
.caption-2 {
	font-size: 20px;
	font-family: Tahoma, Geneva, sans-serif;
	font-weight: bold;
	color: #93F;
}
.caption-3 {
	font-size: 20px;
	font-family: Tahoma, Geneva, sans-serif;
	font-weight: bold;
	color: #F00;
}
.caption-4 {
	font-size: 20px;
	font-family: Tahoma, Geneva, sans-serif;
}
.content {
	font-size: 20px;
	font-family: Tahoma, Geneva, sans-serif;
}
.content a {
	font-size: 20px;
	font-family: Tahoma, Geneva, sans-serif;
	color: #000;
}
.content strong a {
	font-size: 20px;
	font-family: Tahoma, Geneva, sans-serif;
	color: #93F;
}
.title-small {
	font-size: 25px;
	font-family: Georgia, "Times New Roman", Times, serif;
	font-weight: bold;
	color: #F90;
}
.title-large {
	font-size: 34px;
	font-family: Georgia, "Times New Roman", Times, serif;
	font-weight: bold;
	color: #06F;
}
.margin {
	font-size: 15px;
	line-height: 10px;
}
.margin-small {
	font-size: 5px;
	line-height: 5px;
}
.margin-large {
	font-size: 15px;
	line-height: 15px;
}
a:link {
	text-decoration: none;
}
a:visited {
	text-decoration: none;
}
content a:link {
	text-decoration: none;
}
content a:visited {
	text-decoration: none;
}
a:hover {
	text-decoration: underline;
}
a:active {
	text-decoration: underline;
	color: #06F;
}
strong a:active {
	text-decoration: underline;
	color: #06F;
}
</style>
<meta name="google-site-verification" content="VgzQzauhxNIBuURvZ-tTneQRmVL4stD1XYi1wcz7KR8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
</head>


<body>
<table width="100%" border="0">
  <tr>
    <td align ="center" width="180"><img src="images/shisheng.jpeg" height="150" border="0"></td>
    <td width="15"></td>
    <td><table width="100%" border="0">
      <tr height="10">
        <td></td></tr>
      <tr height="55">
        <td><img src="images/name.png" height="55" border="0"></td></tr>
      <tr height="5">
        <td></td></tr>
      <tr height="60">
        <td>
	<p class="margin">&nbsp;</p>
	  <p class="content"><strong>Associate Professor / 副教授 @ <span class="caption-2">
	<a href="https://ai.bnu.edu.cn/" class="caption-2">School of Artificial Intelligence</a></span>, <span class="caption-2">
	<a href="https://www.bnu.edu.cn/" class="caption-2">Beijing Normal University</a></span></p>
	  <p class="margin">&nbsp;</p>
          <p class="content"><strong>Email: &nbsp;</strong>shishenghuang.net@gmail.com &nbsp; huangss@bnu.edu.cn</p>
          <p class="margin-small">&nbsp;</p>
          <!--p class="content"><strong>Address: &nbsp;</strong>FIT Building 3-523, Tsinghua University, Beijing, P.R. China, P.C: 100084.</p-->
          <p class="margin">&nbsp;</p>
		  <!--<p class="content">More information can be found in <strong><a href="cv/Shi-Sheng Huang.pdf">[Curriculum Vitae]</a></strong></p>-->
		  <p class="margin">&nbsp;</p>
        </td></tr>
      <tr height="20">
        <td></td></tr>
    </table></td>
  </tr>
</table>

<p class="margin">&nbsp;</p>

<p class="caption-1">I am an associate professor at <span class="caption-2">
	<a href="https://ai.bnu.edu.cn/" class="caption-2">School of Artificial Intelligence</a></span>, <span class="caption-2">
	<a href="https://www.bnu.edu.cn/" class="caption-2">Beijing Normal University</a></span>. I got my PhD degree from <a href="https://cg.cs.tsinghua.edu.cn/" class="caption-2">Graphics & Geometric Computing Group </a></span>,
	<span class="caption-2"><a href="http://www.tsinghua.edu.cn/publish/then/index.html" class="caption-2">Tsinghua University</a></span> under guidance of <span class="caption-2"><a href="http://cg.cs.tsinghua.edu.cn/prof_hu.htm" class="caption-2">Prof. Shi-Min Hu</a></span> in 2015.</p>
<p class="margin-small">&nbsp;</p>
<!--p class="caption-1">I was the former Chief Technique Officer of <a href="http://www.hyperci.com/" class="caption-2">Hyperception Inc.</a>  </p-->
<p class="margin-small">&nbsp;</p>
<p class="caption-1">My current research interests include:</p>
<p class="margin-small">&nbsp;</p>
<p class="caption-1"><span class="caption-3">- Online 3D Reconstruction</span></p>
<p class="margin-small">&nbsp;</p>
<p class="caption-1"><span class="caption-3">- Dynamic View Synthesis</span></p>
<p class="margin-small">&nbsp;</p>
<p class="caption-1"><span class="caption-3">- Geometric Deep Learning</span></p>
<p class="margin-small">&nbsp;</p>
<p class="caption-1"><span class="caption-3">- 3D Virtual Avatar Reconstruction</span></p>
<!-- <p class="margin-small">&nbsp;</p>
<p class="caption-1"><span class="caption-3">- VR/AI + Education</span></p> -->
<p class="margin-small">&nbsp;</p>
<!--p class="caption-1"><span class="caption-3">- Shape Analysis and Geometry Processing</span></p-->

<p class="margin-small">&nbsp;</p>
<p class="margin">&nbsp;</p>

<p class="margin">&nbsp;</p>
<p id="sect-publications" class="title-large">News</p>
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
<p class="caption-4"><span class="caption-3">2025/02</span> RGAvatar is accepted by IEEE TVCG. Code will be coming soon!</p>	
<p class="caption-4"><span class="caption-3">2024/12</span> One paper is accepted by IEEE VR 2025 (Accepted as TVCG Paper).</p>
<p class="caption-4"><span class="caption-3">2024/09</span> RGAvatar, EGAvatar, Self-SupervisedDepthCompletion  are accepted by IEEE TVCG with major revision.</p>	
<p class="caption-4"><span class="caption-3">2024/06</span> GP-Recon is accepted by IEEE TVCG.</p>	
<p class="caption-4"><span class="caption-3">2024/05</span> One paper is accepted by ICML 2024.</p>	
<p class="caption-4"><span class="caption-3">2024/03</span> One paper is conditionally accepted by SIGGRAPH 2024.</p>
<p class="caption-4"><span class="caption-3">2023/12</span> Two papers are accepted by AAAI 2024.</p>
<p class="caption-4"><span class="caption-3">2023/10</span> One paper is accepted by ACM MM 2023.</p>
<p class="caption-4"><span class="caption-3">2021/12</span> ObjectFusion is accepted by CVM 2022, and recommended to Graphical Models. </p>
<p class="caption-4"><span class="caption-3">2021/12</span> SemanticFusion is accepted by IEEE TVCG. </p>
<p class="caption-4"><span class="caption-3">2021/06</span> I was invited to review papers on SLAM for IEEE RA-L. </p>
<p class="caption-4"><span class="caption-3">2021/03</span> One paper is accepted by ACM TOG. </p>
<p class="caption-4"><span class="caption-3">2021/03</span> DI-Fusion is conditionally accepted by CVPR 2021.</p>
<!-- <p class="caption-4"><span class="caption-3">2020/12</span> One paper is accepted with minor revision by ACM TOG.</p> -->
<p class="caption-4"><span class="caption-3">2020/9/4</span> LC-CRF SLAM is accepted by IEEE TVCG.</p>
<p class="caption-4"><span class="caption-3">2020/1/22</span> Our paper is accepted by ICRA 2020.</p>
<!-- <p class="caption-4"><span class="caption-3">2019/12/24</span> Our paper OC-CRF SLAM is agreed to be published on IEEE TVCG, with approval of EIC of IEEE TVCG.</p>
<p class="caption-4"><span class="caption-3">2019/12/05</span> One paper about RGB-D dynamic SLAM (OC-CRF SLAM) is accepted by CVM 2020.</p> -->
<!--p class="caption-4"><span class="caption-3">2019/07/23</span> One paper about Wheel-based VO was accepted by IEEE Access.</p-->
<!--p class="caption-4"><span class="caption-3">2019/05/20</span> I will begin my postdoc research career soon.</p-->
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>


<p id="sect-publications" class="title-large">Publications</p>


<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<table width="100%" border="0">
	<tr>
<!-- 		<td width="140"><img src="Papers/neuralindicator/neuralindicator.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>NeuralIndicator: Implicit Surface Optimization with Neural Indicator Priors</strong></p>
			<p class="content"><strong>Shi-Sheng Huang</strong>, Hongbo Fu, Hua Huang. </p>
			<p class="content"> <Strong>IEEE transactions on Visualization and Computer Graphics (TVCG)</Strong>, Revision </p>
			<p class="content"> [arXiv] preprint arXiv </p> 
			
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="">[arXiv]</a></strong> <strong><a href="">[Code]</a> </p>
	</td>
	</tr>
</table> -->
		
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/egavatar/system.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>EGAvatar: Efficient GAN Inversion for Generalizable Head Avatar from Few-shot Images</strong></p>
			<p class="content">Hao-Pan Ren, Wei Duan, Wan-Yu Li, Yi Liu, Yu-Dong Guo, <strong>Shi-Sheng Huang</strong>, Ju-Yong Zhang, Hua Huang. </p>
			<p class="content"> <a href="https:1">[arXiv]</a> preprint </p>
			<p class="content"> <Strong>IEEE transactions on Visualization and Computer Graphics (TVCG)</Strong>, Major Revision </p>	
			
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="https://arxiv.org/">[Paper]</a></strong> <strong><a href="">[Code (soon)]</a> </p>
	</td>
	</tr>
</table>
		
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
		
<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/depth/depth.PNG" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>Self-Supervised Depth Completion Guided by 3D Perception and Geometry Consistency</strong></p>
			<p class="content">Yu Cai, Tianyu Shen, <strong>Shi-Sheng Huang</strong>, Hua Huang. </p>
			<p class="content"> <a href="https://arxiv.org/html/2312.15263v1">[arXiv]</a> preprint arXiv:2312.15263 </p>
			<p class="content"> <Strong>IEEE transactions on Visualization and Computer Graphics (TVCG)</Strong>, Major Revision </p>	
			
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="https://arxiv.org/pdf/2312.15263.pdf">[Paper]</a></strong> <strong><a href="">[Code (soon)]</a> </p>
	</td>
	</tr>
</table>
		
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/mixlight/mixlight.PNG" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>MixLight: Borrowing the Best of both Spherical Harmonics and Gaussian Models</strong></p>
			<p class="content">Xinlong Ji, Fangneng Zhan, Shijian Lu, <strong>Shi-Sheng Huang</strong>, Hua Huang. </p>
			<p class="content"> <a href="https://arxiv.org/pdf/2404.12768">[arXiv]</a> preprint arXiv:2404.12768 </p>
			<p class="content"> submit to <Strong>IEEE transactions on Visualization and Computer Graphics (TVCG)</Strong> </p>	
			
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="https://arxiv.org/pdf/2404.12768.pdf">[Paper]</a></strong> <strong><a href="">[Code (soon)]</a> </p>
	</td>
	</tr>
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>		
		
<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/rgavatar/system.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>RGAvatar: Relightable 4D Guassian Avatar from Monocular Videos</strong></p>
			<p class="content">Zhe Fan, <strong>Shi-Sheng Huang</strong>, Yichi Zhang, Dachao Shang, Juyong Zhang, Yudong Guo, Hua Huang. </p>
			<p class="content"> <a href="https:1">[arXiv]</a> preprint </p>
			<p class="content"> <Strong>IEEE transactions on Visualization and Computer Graphics (TVCG)</Strong>, Accept, 2025 </p>	
			
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="Papers/rgavatar/main.pdf">[Paper]</a></strong> <strong><a href="">[Code (soon)]</a> </p>
	</td>
	</tr>
</table>
		
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
		
<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/mpgs/system.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>MPGS: Multi-plane Gaussian Splatting for Compact Scenes Rendering</strong></p>
			<p class="content">Deqi Li, <strong>Shi-Sheng Huang</strong>, Hua Huang. </p>
			<p class="content"> <a href="https:1">[arXiv]</a> preprint </p>
			<p class="content"> <Strong>IEEE VR 2025 (Accepted as TVCG Paper)</Strong></p>	
			
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="https://arxiv.org/">[Paper]</a></strong> <strong><a href="">[Code (soon)]</a> </p>
	</td>
	</tr>
</table>


<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/neuralindicator/neuralindicator.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>NeuralIndicator: Implicit Surface Optimization with Neural Indicator Priors</strong></p>
			<p class="content"><strong>Shi-Sheng Huang*</strong>, Guo Chen, Liheng Chen, Hua Huang</p>
			<p class="content"> <a href="https://arxiv.org/">[arXiv]</a> </p>
			<p class="content"> <Strong>ICML 2024</Strong> </p>	
			
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="https://arxiv.org/">[Paper]</a></strong> <strong><a href="">[Code (soon)]</a> </p>
	</td>
	</tr>
</table>

		
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/monofusion/monofusion.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>GP-Recon: Online Monocular Neural 3D Reconstruction with Geometric Prior</strong></p>
			<p class="content">Zi-Xin Zhou, <strong>Shi-Sheng Huang*</strong>, Yan-Pei Cao, Tai-Jiang Mu, Ying Shan, Hongbo Fu, Song-Hai Zhang*. (* Correpsonding Author)</p>
			<p class="content"> <a href="https://arxiv.org/pdf/2209.15153.pdf">[arXiv]</a> preprint arXiv:2209.15153 </p>
			<p class="content"> <Strong>IEEE transactions on Visualization and Computer Graphics (TVCG)</Strong>, accept </p>	
			
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="https://arxiv.org/pdf/2209.15153.pdf">[Paper]</a></strong> <strong><a href="">[Code (soon)]</a> </p>
	</td>
	</tr>
</table>

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/st4dgs/system.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>ST-4DGS: Spatial-Temporally Consistent 4D Gaussian Splatting for Efficient Dynamic Scene Rendering</strong></p>
			<p class="content">Deqi Li, <strong>Shi-Sheng Huang</strong>, Zhiyuan Lu, Xinran Duan, Hua Huang*. (* Correpsonding Author)</p>
			<p class="content"> <a href="">[arXiv]</a> preprint </p>
			<p class="content"> <Strong>ACM SIGGRAPH 2024</Strong>, Conference </p>	
			
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="">[Paper]</a></strong> <strong><a href="">[Code (soon)]</a> </p>
	</td>
	</tr>
</table>

		
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/sc-neus/system.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>SC-NeuS: Consistent Neural Surface Reconstruction from Sparse and Noisy Views</strong></p>
			<p class="content"><strong>Shi-Sheng Huang</strong>, Zi-Xin Zou, Yi-Chi Zhang,  Yan-Pei Cao, Ying Shan. </p>
			<p class="content"> <Strong>AAAI 2024</Strong>, Accepted </p>
			<p class="content"> <a href="">[arXiv]</a>  </p>
			
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="">[Paper]</a></strong> <strong><a href="">[Code (soon)]</a> </p>
	</td>
	</tr>
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/sparse3d/system.PNG" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>Sparse3d: Distilling multiview-consistent diffusion for object reconstruction from sparse views</strong></p>
			<p class="content">Zi-Xin Zou, Weihao Cheng, Yan-Pei Cao, <strong>Shi-Sheng Huang</strong>, Ying Shan, Song-Hai Zhang. </p>
			<p class="content"> <Strong>AAAI 2024</Strong>, Accepted </p>
			<p class="content"> <a href="">[arXiv]</a>  </p>
			
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="https://arxiv.org/abs/2308.14078">[Paper]</a></strong> <strong><a href="">[Code (soon)]</a> </p>
	</td>
	</tr>
</table>


<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/stfw/system.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>Dynamic View Synthesis with Spatio-Temporal Feature Warping from Sparse Views</strong></p>
			<p class="content">Deqi Li, <strong>Shi-Sheng Huang*</strong>, Tianyu Shen, Hua Huang. (* Correpsonding Author) </p>
			<p class="content"> <Strong>ACM MM 2023</Strong>  <Strong>Accepted</Strong> </p>	
			
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="">[Paper (soon)]</a></strong> <strong><a href="">[Code (soon)]</a> </p>
	</td>
	</tr>
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/objectfusion/teaser.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>ObjectFusion: Accurate Object-level SLAM with Neural Object Priors</strong></p>
			<p class="content">Zi-Xin Zhou, <strong>Shi-Sheng Huang*</strong>, Tai-Jiang Mu, Yu-Ping Wang. (* Correpsonding Author) </p>
			<p class="content"> <Strong>CVM 2022</Strong>, recommended to <Strong>Graphical Models</Strong> </p>	
			
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="Papers/objectfusion/objectfusion.pdf">[Paper]</a></strong> <strong><a href="">[Code [Please contact me for the code]]</a> </p>
	</td>
	</tr>
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/semanticfusion/sfusion.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>Real-Time Globally Consistent 3D Reconstruction with Semantic Priors</strong></p>
			<p class="content"><strong>Shi-Sheng Huang</strong>, HaoXiang Chen, Jiahui Huang, Hongbo Fu, Shi-Min Hu.</p>
			<p class="content"> <Strong>IEEE transactions on Visualization and Computer Graphics (TVCG)</Strong>, Accept, 2021 </p>	
			
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="Papers/semanticfusion/paper.pdf">[Paper]</a></strong> <strong><a href="">[Code [Please contact me for the code]]</a> </p>
	</td>
	</tr>
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/difusion/difusion.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>DI-Fusion: Online Implicit 3D Reconstruction with Deep Priors</strong></p>
			<p class="content">Jiahui Huang, <strong>Shi-Sheng Huang*</strong>, Haoxuan Song, Shi-Min Hu.</p>
			<p class="content"> <strong>IEEE CVPR</strong> 2021:8932-8941 </p>	
			<p class="content"> https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_DI-Fusion_Online_Implicit_3D_Reconstruction_With_Deep_Priors_CVPR_2021_paper.pdf </p>	
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="Papers/difusion/2012.05551.pdf">[ArXiv[3.3M]]</a></strong> <strong><a href="Papers/difusion/DI_Fusion.mp4">[Video[51.2M]]</a> </p>
	</td>
	</tr>
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

 <table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/deepvoxel/deepvoxel.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>Supervoxel Convolution for Online 3D Semantic Segmentation</strong></p>
			<p class="content"><strong>Shi-Sheng Huang</strong>, Ze-Yu Ma, Tai-Jiang Mu, Hongbo Fu, Shi-Min Hu.</p>
			<p class="content"> <strong>ACM Transactions on Graphics</strong>, Vol. 40, No. 3, 2021 </p>	
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="Papers/deepvoxel/">[PDF]</a></strong> <strong><a href="Papers/deepvoxel/">[Video]</a></strong> <strong><a href="Papers/deepvoxel/">[Code [Please contact me for the code]]</a></strong> </p>
	</td>
	</tr>
</table> 


<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/OC-CRF/teaser_tvcg.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>Accurate Dynamic SLAM using CRF-based Long-term Consistency</strong></p>
			<p class="content">Zheng-Jun Du*, <strong>Shi-Sheng Huang*</strong>, Tai-Jiang Mu, Qunhe Zhao, Ralph Martin, Kun Xu.</p>
			<p class="content"> <strong>IEEE transactions on Visualization and Computer Graphics (TVCG)</strong> 2020 </p>
<p class="content"> DOI:10.1109/TVCG.2020.3028218</p>		
<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="Papers/OC-CRF/lccrf_tvcg.pdf">[Print[6.2M]]</a></strong> <strong><a href="Papers/OC-CRF/lccrf_tvcg_supp.pdf">[Supp[3.8M]]</a></strong> <strong><a href="https://github.com/Zhengjun-Du/LC-CRF-SLAM">[Code [via GitHub]]</a></strong> </p>
	</td>
	</tr>
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>


<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/PL_LOAM/plloam_teaser.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>LiDAR-Monocular Visual Odometry using Point and Line Features</strong></p>
			<p class="content"><strong>Shi-Sheng Huang</strong>, Ze-Yu Ma, Tai-Jiang Mu, Hongbo Fu, Shi-Min Hu.</p>
			<p class="content"><strong>ICRA</strong> 2020:1091-1097 </p>
		<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="Papers/PL_LOAM/ICRA_final.pdf">[PrePrint[11.2M]]</a></strong> <strong><a href="Papers/PL_LOAM/paper_1278_attachment_video.mp4">[Video[20M]]</a></strong> <strong><a href="Papers/PL_LOAM/">[Code[soon...]]</a></strong> </p>
	</td>
	</tr>
</table>
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<!--p class="margin">&nbsp;</p-->
<!--p class="margin">&nbsp;</p-->

<!--table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/VO/teaser.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>Tightly-coupled Monocular Visual-odometric SLAM using Wheels and a MEMS Gyroscope</strong></p>
			<p class="content">	Meixiang Quan, Songhao Piao, Minglang Tan, <strong>Shi-Sheng Huang</strong>.</p>
			<p class="content">IEEE Access <Strong>(IF=3.557)</Strong> 7: 97374-97389 (2019)</p>
		<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="Papers/VO/vo_preprint.pdf">[PrePrint[2M]]</a></strong> </p>
	</td>
	</tr>
</table -->

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/OC-CRF/teaser_occrf.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>Accurate RGB-D SLAM in Dynamic Environments using Observationally Consistent Conditional Random Fields</strong></p>
			<p class="content">Zheng-Jun Du, <strong>Shi-Sheng Huang</strong>, Tai-Jiang Mu, Qunhe Zhao, Ralph Martin, Kun Xu.</p>
			<p class="content">Accepted by <strong>CVM</strong> 2020 </p>
 		<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="Papers/OC-CRF/paper6.pdf">[Print[6.4M]]</a></strong> <strong><a href="Papers/OC-CRF/oc-crf-video.mp4">[Video[44M]]</a></strong> <strong><a href="Papers/OC-CRF/">[Code[XM]]</a></strong> </p>
	</td>
	</tr>
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<!--table width="100%" border="0">
  <tr>
    <td width="140"><img src="Papers/VIO/teaser.png" width="140" border='1' /></td>
    <td width="20"></td>
    <td><p class="title-small"><strong>Accurate Monocular Visual-Inertial SLAM using a Map-Assisted EKF Approach</strong></p>
      <p class="content">	Meixiang Quan, Songhao Piao, Minglang Tan, <strong>Shi-Sheng Huang</strong>.</p>
	  <p class="content">IEEE Access <Strong>(IF=3.557)</Strong> 7: 34289-34300 (2019)</p>
		<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="Papers/VIO/vio_preprint.pdf">[Paper[1.4M]]</a></strong> </p>
	</td>
  </tr>
</table-->

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
<table width="100%" border="0">
		<tr>
			<td width="140"><img src="Papers/functionality/teaser.png" width="140" border='1' /></td>
			<td width="20"></td>
			<td><p class="title-small"><strong>Support Substructures: Support-Induced Part-Level Structural Representation</strong></p>
				<p class="content"><strong>Shi-Sheng Huang</strong>, <a href="http://sweb.cityu.edu.hk/hongbofu/">Hongbo Fu</a>, Ling-Yu Wei, and <a href="http://cg.cs.tsinghua.edu.cn/prof_hu.htm">Shi-Min Hu</a>.</p>
			<p class="content"><Strong>IEEE transactions on Visualization and Computer Graphics (TVCG)</Strong>, 22(8): 2024-2036 (2016).</p>
			<p class="content"><strong><a href="Papers/functionality/functionality_preprint.pdf">[Paper[1.7M]]</a></strong> </p>		
		</td>
		</tr>	 
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
<table width="100%" border="0">
		<tr>
			<td width="140"><img src="Papers/scene/teaser.png" width="140" border='1' /></td>
			<td width="20"></td>
			<td><p class="title-small"><strong>Structure guided interior scene synthesis via graph matching</strong></p>
				<p class="content"><strong>Shi-Sheng Huang</strong>, <a href="http://sweb.cityu.edu.hk/hongbofu/">Hongbo Fu</a>, and <a href="http://cg.cs.tsinghua.edu.cn/prof_hu.htm">Shi-Min Hu</a>.</p>
			<p class="content"><Strong>Graphical Models</Strong>, 85: 46-55 (2016).</p>
			<p class="content"><strong><a href="Papers/scene/scene_paper.pdf">[Paper[2.9M]]</a></strong> </p>			
		</td>
		</tr>	 
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
<table width="100%" border="0">
  <tr>
    <td width="140"><img src="Papers/metafilter/teaser.png" width="140" border='1' /></td>
    <td width="20"></td>
    <td><p class="title-small"><strong>Parametric Meta-Filter Modeling from a Single Example Pair</strong></p>
      <p class="content"><strong>Shi-Sheng Huang</strong>, Guo-Xin Zhang, <a href="https://users.cs.cf.ac.uk/Yukun.Lai/">Yu-Kun Lai</a>, <a href="http://johanneskopf.de/">Johannes Kopf</a>, <a href="http://www.cs.tau.ac.il/~dcor/">Daniel Cohen-Or</a>, and <a href="http://cg.cs.tsinghua.edu.cn/prof_hu.htm">Shi-Min Hu</a>.</p>
      <p class="content">Accepted by <Strong>CGI 2014</Strong>, The Visual Computer 30(6-8): 673-684 (2014).</p>
      <p class="margin-small">&nbsp;</p>
      <p class="content"><strong><a href="http://cg.cs.tsinghua.edu.cn/people/~shisheng/project/metafilter/index.htm">[Project Page]</a></strong><strong><a href="Papers/metafilter/metafilter_paper.pdf">[PrePrint[3M]]</a></strong></p>
      </td>
  </tr>
 
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
<p class="margin-small">&nbsp;</p>
<table width="100%" border="0">
  <tr>
    <td width="140"><img src="Papers/quartet/teaser.png" width="140" border='1' /></td>
    <td width="20"></td>
    <td><p class="title-small"><strong>Qualitative Organization of Collections of Shapes via Quartet Analysis</strong></p>
      <p class="content"><strong>Shi-Sheng Huang</strong>, <a href="http://www.faculty.idc.ac.il/arik/">Ariel Shamir</a>, <a href="http://cg.cs.tsinghua.edu.cn/people/~chaohui/">Chao-Hui Shen</a>, <a href="http://www.cs.sfu.ca/~haoz/">Hao Zhang</a>, <a href="http://www.cs.ubc.ca/~sheffa/">Alla Sheffer</a>, <a href="http://cg.cs.tsinghua.edu.cn/prof_hu.htm">Shi-Min Hu</a>, and <a href="http://www.cs.tau.ac.il/~dcor/">Daniel Cohen-Or</a>.</p>
      <p class="content">ACM Transactions on Graphics (Proceedings of <Strong>SIGGRAPH 2013</Strong>), 32(4): 71:1-71:10 (2013).</p>
      <p class="margin-small">&nbsp;</p>
      <p class="content"><strong><a href="http://cg.cs.tsinghua.edu.cn/quartet/">[Project Page]</a></strong> <strong><a href="Papers/quartet/Quartet_low_res.pdf">[Paper[9M]]</a></strong> </p>
      </td>
  </tr>
 
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
<p class="margin-small">&nbsp;</p>
<table width="100%" border="0">
  <tr>
    <td width="140"><img src="Papers/facade/teaser.png" width="150" border='1' /></td>
    <td width="20"></td>
    <td><p class="title-small"><strong>Adaptive Partitioning of Urban Facades</strong></p>
      <p class="content"><a href="http://cg.cs.tsinghua.edu.cn/people/~chaohui/">Chao-Hui Shen</a>, <Strong>Shi-Sheng Huang</Strong>, <a href="http://sweb.cityu.edu.hk/hongbofu/">Hongbo Fu</a>, <a href="http://cg.cs.tsinghua.edu.cn/prof_hu.htm">Shi-Min Hu</a>.</p>
      <p class="content">ACM Transactions on Graphics (Proceedings of <Strong>SIGGRAPH Asia 2011</Strong>), 30(6): Article 184.</p>
      <p class="margin-small">&nbsp;</p>
      <p class="content"><strong><a href="http://cg.cs.tsinghua.edu.cn/AdaptivePartitioning">[Project Page]</a></strong><strong><a href="Papers/facade/facade_paper.pdf">[Paper[4.3M]]</a></strong></p>
   </tr>
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
<p class="margin-small">&nbsp;</p>
<table width="100%" border="0">
  <tr>
    <td width="140"><img src="Papers/Popup/teaser.png" width="140" border='1' /></td>
    <td width="20"></td>
    <td><p class="title-small"><strong>Popup: Automatic Paper Architectures from 3D Models</strong></p>
      <p class="content"><a href="http://cg.cs.tsinghua.edu.cn/people/~xianying/">Xian-Ying Li</a>, <a href="http://cg.cs.tsinghua.edu.cn/people/~chaohui/">Chao-Hui Shen</a>, <Strong>Shi-Sheng Huang</Strong>, <a href="http://www.cs.wustl.edu/~taoju/">Tao Ju</a>, and <a href="http://cg.cs.tsinghua.edu.cn/prof_hu.htm">Shi-Min Hu</a>.</p>
      <p class="content">ACM Transactions on Graphics (Proceedings of <Strong>SIGGRAPH 2010</Strong>), 29(4): article 111.</p>
      <p class="margin-small">&nbsp;</p>
      <p class="content"><strong><a href="http://cg.cs.tsinghua.edu.cn/people/~xianying/Papers/Popup/index.html">[Project Page]</a></strong><strong><a href="Papers/Popup/popup_paper.pdf">[Paper[1.6M]]</a></strong></p>
      </td>
  </tr>
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<p id="sect-publications" class="title-large">Technique Report</p>
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
<p class="content">I spent about two years on multi-sensor-fusion-based vSLAM for a low-cost commercial vaccum cleaner robots, including mono-VIO, mono-odometry, mono-inertial-odometry vSLAM etc. There following two works are the reprensentive works with some of which were successfully applied on products like <strong><a href="https://www.bobsweep.com/bob-pethair-vision">[Bob-Pethair-Vision].</a></strong>.</p>
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/VIO/teaser.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>Accurate Monocular Visual-inertial SLAM using a Map-assisted EKF Approach</strong></p>
			<p class="content">arXiv: https://arxiv.org/abs/1706.03648 </p>
                        <p class="content">This is a high accurate monocular VIO SLAM system, especially on the initialization of Cam-IMU setup</p>
		<p class="margin-small">&nbsp/p;</p>
		<p class="content"><strong><a href="https://arxiv.org/abs/1706.03648">[arXiv]</a></strong> </p>
	</td>
	</tr>
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<table width="100%" border="0">
	<tr>
		<td width="140"><img src="Papers/VO/teaser.png" width="140" border='1' /></td>
		<td width="20"></td>
		<td><p class="title-small"><strong>Tightly-coupled Monocular Visual-odometric SLAM using Wheels and a MEMS Gyroscope</strong></p>
			<p class="content">arXiv: https://arxiv.org/abs/1804.04854 </p>
                        <p class="content">This is a high accurate monocular-odometry SLAM system, which is the origin of VSLAM Navigation product of Vaccum Cleaner</p>
		<p class="margin-small">&nbsp;</p>
		<p class="content"><strong><a href="https://arxiv.org/abs/1804.04854">[arXiv]</a> </p>
	</td>
	</tr>
</table>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
<p id="sect-publications" class="title-large">Code/Software</p>
<p class="content"> For a Visual-SLAM beginner, you had better prepare a math library for solving the factor graph based Bundle Adjustment problems. I preprared a math library with point-, line-, plane- reprojection factors called <strong>MyG2O</strong>, please try it! </p>
<p class="content"> 对于视觉SLAM初学者来说,一个功能完整的数学库(用于求解BundleAdjustment)往往很重要.我准备了一个这样的数学库叫<strong>MyG2O</strong>, please try it! </p>
<p class="content"><strong><a href="Papers/factors/factors.pdf">[PrePrint[~1M]]</a></strong> <strong><a href="https://github.com/shishenghuang/MyG2O">[Code[GitHub]]</a></strong> </p>

<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<p class="margin-large">&nbsp;</p>
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>


<p id="sect-education" class="title-small">Education and Experience</p>
<p class = "margin">&nbsp</p>

<p class="caption-1">I was a postdoc researcher at <span class="caption-2">
	<a href="https://cg.cs.tsinghua.edu.cn/" class="caption-2">Graphics & Geometric Computing Group </a></span>,
	<span class="caption-2"><a href="http://www.tsinghua.edu.cn/publish/then/index.html" class="caption-2">Tsinghua University</a></span> in Beijing, working with <span class="caption-2"><a href="http://cg.cs.tsinghua.edu.cn/prof_hu.htm" class="caption-2">Prof. Shi-Min Hu</a></span>.</p>
<p class="margin-small">&nbsp;</p>
<p class="caption-1">I got my PhD degree from <span class="caption-2"><a href="http://cg.cs.tsinghua.edu.cn/" class="caption-2">Graphics and Geometric Computing Group</a></span> in 2015.</p>
<p class="margin-small">&nbsp;</p>

<table width = "100%" border="0">
	<tr>
		<td  width = "40" class = "content">2012.9-2013.2</td>
		<td  width = "10" class = "content">&nbsp;</td>
		<td  width = "260" class = "content"><span class="caption-2"><a href="http://english.tau.ac.il/" class="caption-2">Tel-Aviv University</a></span> and <span class="caption-2"><a href="http://portal.idc.ac.il/en/main/homepage/Pages/homepage.aspx" class="caption-2">IDC(Herzliya)</a></span>, Israel</td>
		<td  width = "10" class = "content">&nbsp;</td>
		<td  width = "140" class = "content">Visiting Scholar PhD Student.</td>
	</tr>
	<tr>
		<td  width = "40" class = "content">2011.9-2011.11</td>
		<td  width = "10" class = "content">&nbsp;</td>
		<td  width = "260" class = "content"><span class="caption-2"><a href="http://www.scm.cityu.edu.hk/" class="caption-2"> School of Creative Media</a></span>, <span class="caption-2"><a href="http://www.cityu.edu.hk/" class="caption-2">City Univ. of Hong Kong</a></span>, Hong Kong </td>
		<td  width = "10" class = "content">&nbsp;</td>
		<td  width = "140" class = "content">Visiting Research Assistant</td>
	</tr>
</table>
<p class = "margin">&nbsp;</p>
<table width = "100%" border="0">	
	<tr>
		<td  width = "40" class = "content">2010.9-2015.10</td>
		<td  width = "10" class = "content">&nbsp;</td>
		<td  width = "260" class = "content">Department of Computer Science and Technology, <span class="caption-2"><a href="http://www.tsinghua.edu.cn/publish/then/index.html" class="caption-2">Tsinghua University</a></span></td>
		<td  width = "10" class = "content">&nbsp;</td>
		<td  width = "140" class = "content">PhD Degree.</td>
	</tr>
	<tr>
		<td  width = "40" class = "content">2006.9-2010.7</td>
		<td  width = "10" class = "content">&nbsp;</td>
		<td  width = "260" class = "content">Information and Computation, School of Science, <span class="caption-2"><a href="http://en.njtu.edu.cn/" class="caption-2">Beijing Jiao-Tong University</a></span></td>
		<td  width = "10" class = "content">&nbsp;</td>
		<td  width = "140" class = "content">Bachlor Degree, with Honor (Ranked Top 1%.)</td>
	</tr>
</table>
<p class="margin">&nbsp;</p>

<p class="title-small">Collaborators</p>
<p class="margin">&nbsp;</p>
<p class="content"><a href="http://cg.cs.tsinghua.edu.cn/prof_hu.htm">Prof. Shi-Min Hu</a>, <a href="http://sweb.cityu.edu.hk/hongbofu/">Prof. Hongbo Fu</a>, <a href="http://cg.cs.tsinghua.edu.cn/people/~kun/">Prof. Kun Xu</a>, <a href="http://users.cs.cf.ac.uk/Yukun.Lai/">Prof. Yu-Kun Lai</a></p>
<p class="margin">&nbsp;</p>
<p class="content"><a href="http://www.cs.tau.ac.il/~dcor/">Prof. Daniel Cohen-Or</a>, <a href="http://www.faculty.idc.ac.il/arik/"> Prof. Ariel Shamir</a>, 
 <a href="http://www.cs.sfu.ca/~haoz/">Prof. Hao Zhang</a>, <a href="http://www.cs.ubc.ca/~sheffa/">Prof. Alla Sheffer</a>, <a href="http://www.cs.wustl.edu/~taoju/">Prof. Tao Ju</a>, <a href="http://johanneskopf.de/">Dr. Johannes Kopf</a></p>

<p class="margin">&nbsp;</p>
<p class="content">My Friends:</p>
<p class="margin">&nbsp;</p>
<p class="content"><a href="http://cg.cs.tsinghua.edu.cn/people/~chaohui/">Chao-Hui Shen</a>, <a href="http://cg.cs.tsinghua.edu.cn/people/~xianying/">Xian-Ying Li</a>, <a href="">Guo-Xin Zhang</a></p>
<p class="margin">&nbsp;</p>
<p class="content"><a href="http://geometrylearning.com/">Lin Gao</a>, <a href="https://ecs.wgtn.ac.nz/Main/FanglueZhang">Fang-Lue Zhang</a>, <a href="http://miaowang.me/">Miao Wang</a>,<a href="https://cg.cs.tsinghua.edu.cn/people/~mtj/">Tai-Jiang Mu</a></p>
<p class="margin">&nbsp;</p>

<p class="margin-large">&nbsp;</p>

<p class="title-small">Academic Services</p>
<p class="margin">&nbsp;</p>
<p class="content">Reviewer. SIGGRAPH 2023, SIGGRAPH Asia 2023, SIGGRAPH 2024</p>
<p class="content">Reviewer. IEEE VR 2021,2023,2024</p>
<p class="content">Reviewer. EG 2021</p>
<p class="content">Reviewer. PG 2020</p>
<p class="content">Reviewer. GMP 2020</p>
<p class="content">Reviewer. CVM 2013, 2015, 2020</p>
<p class="content">Reviewer. SIGGRAPH 2014,2015, SIGA 2014</p>
<p class="content">Reviewer. Journal Computers & Graphics 2013, 2014, 2015</p>
<p class="content">Reviewer. the Visual Computer 2014, 2015</p>
<p class="content">Reviewer. CAG-D 2014,2015, SPM 2014,2015, 2021, CGI 2013,2014,2015</p>
<p class="content">Reviewer. IEEE TVCG 2014, 2015</p>
<p class="content">Reviewer. SGP 2015, EG 2015</p>
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<p class="title-small">Funding</p>
<p class="margin">&nbsp;</p>
<p class="content">China Postdoctoral Science Foundation (Grant No.: 2019M660646)</p>
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<p class="title-small">Awards and Honors</p>
<p class="margin">&nbsp;</p>
<p class="content">2013      - Tsinghua Friends--Tencent Outstanding Innovation Scholarship Award</p>
<p class="content">2010      - Outstanding College Graduates in Beijing, Outstanding College Graduates of Beijing Jiao-Tong University.</p>
<p class="content">2009      - <Strong>Yi-Seng Mao Scholar</Strong>, Yi-Sheng Mao Science and Education Foundation.</p>
<p class="content">2006-2010 - Many Kinds of Scholars and Honors in Beijing Jiao-Tong University.</p>
<p class="content">2005      - Outstanding High School Student in Hunan.</p>
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<!--p id="sect-education" class="title-small">Work Experience</p>
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>
<p class="caption-1">I was the Chief Technique Officer of <a href="http://www.hyperci.com/" class="caption-2">Hyperception Inc.</a>  </p-->

<p class="margin-large">&nbsp;</p>
<p class="margin">&nbsp;</p>
<p class="margin">&nbsp;</p>

<div align="center">
<p class="content">Notice: All the digital  papers and videos in this page are the authors' version for personal use only.</p>
<p class="content">Last updated by Shi-Sheng Huang, May, 2021 in Beijing.</p>
<!--a href="http://www2.clustrmaps.com/user/c8910ac8a"><img src="http://www2.clustrmaps.com/stats/maps-no_clusters/cg.cs.tsinghua.edu.cn/people/~shisheng/index.html-thumb.jpg" alt="Locations of visitors to this page" /></a-->
<a href="https://clustrmaps.com/site/1bisw"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=lkb0iwAV3bAGB5EUMURIz6PS1D6VjFSqt49li5aEuzY&cl=ffffff" /></a>
</div>
</body>
</html>

